rm(list=ls())
library(rrcov)
library(data.table)
library(dplyr)
Sys.setenv(HDF5_USE_FILE_LOCKING='FALSE')
Sys.setenv(OPENBLAS_NUM_THREADS="1")
temp <- commandArgs(TRUE)
set =  as.numeric(temp[1])

#### local: set = 5:24
setwd("/users/jjin/sem/")
library(corpcor) # campute partial correlation from correlation matrix
library(devtools)
library(Rcpp)
library(RcppArmadillo)
library(inline)
library(glasso)
library(CVglasso)
library(mvtnorm)
library(expm) # for sqrtm
library(Hotelling)
library(MASS)
library(parallel)
library(highD2pop)  # R package from GCT paper (2015)
library(highmean)
library(DEGraph) # for Graph.T2
library(graph)
library(rrcov)
n.cores = 10 # ~50 on cluster
alpha = 0.05 # level of type I error control
nrepeat = 1000 # the number of simulations used to calculate the type I error rate for each replicate
Kappa = 1e-5
population = c("X","Y")
signal.dist = "normal"
Qs = 1.5 # 1/|Q|, only used when graph.type = "DAG"
reduced = F#"bias_correction" #FALSE or "bias_correction" or c("eigendecomp-small", "eigendecomp-large","SEMdecomp-large","SEMdecomp-small") # whether or not we run the proposed model with dimension reduction
#p.eigen = c(0.20,0.15,0.1,0.05)
variable = "signal" # the x axis of the power curve q or signal
# the maximum of the signal should change according to the signal sparsity (aSPU)
A.type = "Sparse" # Sparse or HubNode
graph.type = "DAG" # c("DAG","undirected")
signal.type = "equal" # c("equal", "unequal")
n.signals = 10
Rvar.type = "equal"
Rvar = 0.2
error = F# c('Missing','Redundant','Both')
error.percentage = 0 # have to define it: it's an argument of the functions 0.1, 0.2, 0.4.
source("code/rfunctions.R")
lambdas = c(1:6,Inf)
graphT2.p = 0.8
p.non0.C = 0.2
v.confounder = 0.2

#### potential confounders:
# age, sex, principal components
# eQTL? that will make it harder
#################### Simulations ##################
######## Model parameters:
n.p.setting = matrix(c(50,20,50,40,50,50,50,100,100,100,100,200,50,200),ncol=2,byrow = T)
colnames(n.p.setting) = c('n','p')
setting = expand.grid(n.p.indx = 1:nrow(n.p.setting),Q.type=c('equal'),p0=c(0.4,0.8),n.confounder = c(2)) # ,signal.type=c("equal","unequal"),Rvar.type=c("equal","geometric","spike"),,signal.dist = c("normal","gamma"),Q.type = "unequal"

  nx = ny = n.p.setting[setting[set,"n.p.indx"],'n'] # sample size
  n = list(X=nx,Y=ny)
  N = n[['X']]+n[['Y']] ### in BS paper 'n' = N-2
  nmin = min(nx,ny) # minimum sample size
  p = n.p.setting[setting[set,"n.p.indx"],'p'] #number of nodes
  conf1.causal = rep(1,p)
  p0=setting[set,'p0'] * p + ifelse(setting[set,'p0'] == 1, -1, 0)
  set.seed(2020*set)
  if (setting[set,'p0'] == 0.4) d = rnbinom(n=p0,size=1,prob=0.6) + 1
  if (setting[set,'p0'] == 0.8) d = rnbinom(n=p0,size=1,prob=0.8) + 1 # a vector of the # of nonzero entries in each row
  #d = rnbinom(n=p0,size=1,prob=0.8) + 1 # a vector of the # of nonzero entries in each row
  d = sort(d)
  n.confounder = setting[set,"n.confounder"]
  rho2.c2 = 0.2
  if (n.confounder == 3) cor.c2 = matrix(c(1,rho2.c2,rho2.c2,1),2,2)
  if (n.confounder == 2) cor.c2 = rho2.c2
  non0.C = matrix(0,p,n.confounder)
  non0.C.index = sample(1:length(non0.C),p.non0.C*length(non0.C),replace=F)
  non0.C[non0.C.index] = 1

  #### only consider confounders but no errors:
  if (n.confounder > 0)
  {
    if ((N<=p)&(p<50))
    {
      methods = c("GraphSEM.clx","GraphSEM.z","Graph.T2","BS","CH-Q","SK","CLX","GCT")
    }
    if ((N<=p)&(p>=50))
    {
      methods = c("GraphSEM.clx","GraphSEM.z","Graph.T2","BS","CH-Q","SK","CLX","GCT","aSPU")
    }
    if ((N>p)&(p<50))
    {
      methods = c("GraphSEM.clx","GraphSEM.z","Graph.T2","T2","BS","CH-Q","SK","CLX","GCT")
    }
    if ((N>p)&(p>=50))
    {
      methods = c("GraphSEM.clx","GraphSEM.z","Graph.T2","T2","BS","CH-Q","SK","CLX","GCT","aSPU")
    }
  }
  Q.type = setting[set,"Q.type"] # equal or unqual
  ######## Generate graph
  if (Rvar.type == "equal")
  {
    Ris = rep(Rvar,p+n.confounder)
  }
  if (Rvar.type == "geometric")
  {
    var.v = 1.1
    lb.var = 0.01
    Ris = sqrt(geomSeries(base=var.v, max=var.v^(p+n.confounder-1)) * lb.var)
  }
  if (Rvar.type == "spike")
  {
    Ris = c(rep(0.01,floor(0.8*(p+n.confounder))),rep(100,floor(0.2*(p+n.confounder))))
  }

  graphinfo = create.graph(graph.type,A.type,Q.type,d,p,p0,error,error.percentage)
  Qx = graphinfo$Qx
  Qy = graphinfo$Qy
  Sx = graphinfo$Sx
  Sy = graphinfo$Sy
  A = graphinfo$A
  Asign = graphinfo$Asign

  if ('Missing' %in% error)
  {
    AMissing = graphinfo$AMissing
  }
  if ('Redundant' %in% error)
  {
    ARedundant = graphinfo$ARedundant
  }
  if ('Both' %in% error)
  {
    ABoth = graphinfo$ABoth
  }
  #if (variable == "signal")
  #{
    #for (q in ceiling(quantile(0:p,c(0.25,0.5,0.75,1))))
    for (q in sort(unique(c(2,c(0.1,0.2,0.5,1)*p))))
    {
      #q=p #assume that the signals exist in all dimensions
      ###### define signal based on n and p
      conf1.causal = rep(1,p)  #####################################
      ############## this part needs to be fixed!!!
      signal.max = 1.15*0.68*50*(p^(1/6))/(sqrt(q)*n[[1]]*(50^(1/6))) * ifelse(n.confounder > 0, 1+0.1*n.confounder, 1) * ifelse(n[[1]]>=100,1,0.75)
      #0.7*sqrt(50)/sqrt(n[[1]]*q) #0.7*50/(sqrt(q)*n[[1]])
      signals = seq(0,signal.max,by=signal.max/(n.signals))

      aspu.lambda = matrix(NA,length(signals),length(lambdas))
      simresults = list()
      rejpercent = matrix(NA,length(signals),length(methods))
      colnames(rejpercent) = methods
      rownames(rejpercent) = 1:length(signals)
      signalinfo = list()
      for (i in 1:length(signals))
      {
        signalinfo[[i]] = create.signal(signal.type,p,q,signals[i])
        mux = signalinfo[[i]]$mux
        muy = signalinfo[[i]]$muy
        simresults[[i]]=mclapply(1:nrepeat,FUN=function(x){simulation_graph(x,graph.type,error)},mc.cores=n.cores)
        rejpercent[i,] = rowMeans(sapply(1:nrepeat,FUN=function(x){simresults[[i]][[x]]$rej}))
        k=simresults[[i]][[1]]$k
        if (p>=50)
        {
          #aspulambda = sapply(1:nrepeat,FUN=function(x){simresults[[i]][[x]]$aspu.lambda})
          #aspu.lambda[i,]= sapply(1:length(lambdas),function(x){sum(aspulambda == lambdas[x])})
          print(paste0("Complete q=",q,", signal=",round(signals[i],3)))
          save(A,simresults,rejpercent,k,
               file=paste0("/dcl01/chatterj/data/jin/T2DAG/result-1120/sim-confounder-n1=n2=",n[["Y"]],"-p=",p,"-q=",q,"-p0=",p0,"-Qtype=",Q.type,"-Rvar=",Rvar.type,"-",Rvar,"-n.conf=",n.confounder,".RData"))
        }
        if (p<50)
        {
          print(paste0("Complete q=",q,", signal=",round(signals[i],3)))
          save(A,simresults,rejpercent,k,
               file=paste0("/dcl01/chatterj/data/jin/T2DAG/result-1120/sim-confounder-n1=n2=",n[["Y"]],"-p=",p,"-q=",q,"-p0=",p0,"-Qtype=",Q.type,"-Rvar=",Rvar.type,"-",Rvar,"-n.conf=",n.confounder,".RData"))
        }
      }
    }
  #}
#}

